{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from DatasetClassifier.dataset.Dataset import CustomImageDataset\n",
    "from model.BinaryClassifier import BinaryClassifier\n",
    "\n",
    "import copy, wandb\n",
    "from sys import float_info\n",
    "from tqdm import tqdm   \n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "dataset_dir = \"BinaryClassifierDataset\"\n",
    "\n",
    "training_settings = {\n",
    "    \"epochs\" : 100,\n",
    "    \"batch_size\" : 32,\n",
    "    \"learning_rate\" : 3e-4,\n",
    "    \"verbose\" : False,  \n",
    "    \"logging\" : True,\n",
    "    \"save_path\" : \"DatasetClassifier\\\\models\"\n",
    "}\n",
    "\n",
    "\n",
    "# Dataset Transformations\n",
    "preprocessor = Compose([\n",
    "    ToTensor(), \n",
    "    Resize((640, 640), antialias=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def loss_batch(loss_func, predictions, target_labels, optimizer):\n",
    "    \n",
    "    loss_value = loss_func(predictions, target_labels) \n",
    "    pred = predictions.argmax(dim=1, keepdim=True)\n",
    "    metric_b = pred.eq(target_labels.view_as(pred)).sum().item() # get performance metric\n",
    "    \n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_value.item(), metric_b\n",
    "\n",
    "\n",
    "# Compute the loss value & performance metric for the entire dataset (epoch)\n",
    "def loss_epoch(model, loss_func, dataloader: DataLoader, optimizer):\n",
    "    \n",
    "    loss_e = 0.0 \n",
    "    metric_e = 0.0\n",
    "    len_data = len(dataloader.dataset)\n",
    "\n",
    "    # Loop over dataset\n",
    "    progress_bar = tqdm(dataloader)\n",
    "    for images, labels in progress_bar:\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predictions = model(images)\n",
    "        # Get loss per batch\n",
    "        loss_b, metric_b = loss_batch(loss_func, predictions, labels, optimizer) \n",
    "\n",
    "        if optimizer is not None:\n",
    "            progress_bar.set_description(f\"LR: {get_lr(optimizer)} | Loss: {loss_b:.3f} | Acc: {(metric_b/dataloader.batch_size):.3f}\")\n",
    "            if training_settings[\"logging\"]:    \n",
    "                wandb.log({\"batch_train_accuracy\": metric_b, \"batch_train_loss\": loss_b})\n",
    "        else:\n",
    "            progress_bar.set_description(f\"Loss: {loss_b:.3f} | Acc: {(metric_b/dataloader.batch_size):.3f}\")\n",
    "            if training_settings[\"logging\"]:    \n",
    "                wandb.log({\"batch_val_accuracy\": metric_b, \"batch_val_loss\": loss_b})\n",
    "\n",
    "        loss_e += loss_b        \n",
    "\n",
    "        if metric_b is not None: \n",
    "            metric_e += metric_b    \n",
    "    \n",
    "    loss = loss_e / float(len_data)  # average loss value\n",
    "    metric = metric_e / float(len_data) # average metric value\n",
    "    \n",
    "    return loss, metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_settings[\"logging\"]:\n",
    "    wandb.init(\n",
    "    project=\"BinaryClassifier\",\n",
    "    config={\n",
    "        \"learning_rate\": training_settings[\"learning_rate\"],\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"Discarded RoboTo Images\",\n",
    "        \"epochs\": training_settings[\"epochs\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "model = BinaryClassifier(dimensions= (3, 640, 640), num_classes= 2).to(device=device)\n",
    "dataset = CustomImageDataset(annotations_file= dataset_dir+\"\\\\labels\\\\labels.csv\", \n",
    "                                img_dir= dataset_dir+\"\\\\images\",\n",
    "                                transform= preprocessor)\n",
    "\n",
    "if training_settings[\"verbose\"]:\n",
    "    summary(model, input_size=(3, 640, 640), device=device.type)\n",
    "    print(f\"Model Output: {model(torch.rand(1, 3, 640, 640))}\")\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [0.8, 0.2], generator=generator)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=training_settings[\"batch_size\"], shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=training_settings[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# TRAINING\n",
    "loss_func = nn.NLLLoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_settings[\"learning_rate\"])\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=1)\n",
    "best_loss = float_info.max\n",
    "\n",
    "progress_bar = tqdm(range(training_settings[\"epochs\"]))\n",
    "for i, epoch in enumerate(progress_bar):\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_metric = loss_epoch(model, loss_func, train_dataloader, optimizer)\n",
    "    if training_settings[\"logging\"]:\n",
    "        wandb.log({\"epoch_train_accuracy\": train_metric, \"epoch_train_loss\": train_loss})\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_metric = loss_epoch(model, loss_func, valid_dataloader, None)\n",
    "        \n",
    "        if training_settings[\"logging\"]:\n",
    "            wandb.log({\"epoch_val_accuracy\": val_metric, \"epoch_val_loss\": val_loss})\n",
    "    \n",
    "    progress_bar.set_description(f\"Epoch: {i+1} | LR: {get_lr(optimizer):.3f} | Loss: {train_loss:.3f} | Acc: {train_metric:.3f}\")\n",
    "\n",
    "    # Store best model\n",
    "    if(val_loss < best_loss):\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # store weights into a local file\n",
    "        torch.save(model.state_dict(), training_settings[\"save_path\"]+\"\\\\best_model.pt\")\n",
    "        if training_settings[\"verbose\"]:\n",
    "            print(\"Copied best model weights!\")\n",
    "\n",
    "if training_settings[\"logging\"]:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Allowed\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "model = BinaryClassifier(dimensions= (3, 640, 640), num_classes= 2)\n",
    "model.load_state_dict(torch.load(\"trained_model/best_model.pt\", map_location = device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "image_path = \"./test_img.jpg\"\n",
    "image = Image.open(image_path)\n",
    "image = preprocessor(image)\n",
    "image = image.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = model(image).argmax(dim=1, keepdim=True)\n",
    "\n",
    "  print(\"Allowed\" if output.item() else \"Not Allowed\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roboto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
